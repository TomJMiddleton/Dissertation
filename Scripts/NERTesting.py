import torch
import pandas as pd
import spacy
import logging
from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline
from datasets import load_dataset
from seqeval.metrics import classification_report
from seqeval.scheme import IOB2


logger = logging.getLogger(__name__)


def AlignTokens(spacy_tokens, original_tokens):
    """
    Align tokens from spaCy's tokenization with the dataset's tokenisation structure
    ----------
    Parameters:
    spacy_tokens : List[str]
        Tokens generated by spaCy's tokenizer.
    original_tokens : List[str]
        Original tokens from the dataset.
    ----------
    Returns:
    alignment : Dict[int, int]
        A dictionary mapping spaCy token indices to original token indices.
    """
    alignment = {}
    spacy_idx = 0
    orig_idx = 0
    while spacy_idx < len(spacy_tokens) and orig_idx < len(original_tokens):
        if spacy_tokens[spacy_idx] == original_tokens[orig_idx]:
            alignment[spacy_idx] = orig_idx
            spacy_idx += 1
            orig_idx += 1
        elif spacy_tokens[spacy_idx].startswith(original_tokens[orig_idx]):
            alignment[spacy_idx] = orig_idx
            spacy_idx += 1
        else:
            orig_idx += 1
    return alignment

def GetSpacyPredictions(nlp, sentences, original_tokens):
    """
    For a list of sentences:
        generate the predictions from the model
        align these predictions with the original words in the sentence.
        convert labels to the IOB format
    ----------
    Parameters:
    nlp : spacy.lang
        Loaded spacy model.
    sentences : List[str]
        List of sentences to process.
    original_tokens : List[List[str]]
        Original tokens for each sentence.
    ----------
    Returns:
    all_predictions : List[List[str]]
        Predictions for each word in each sentence, in IOB2 tagging format.
    """
    all_predictions = []
    
    # Map Spacy labels to CoNLL-2003 labels
    label_map = {
        'PERSON': 'PER', 'ORG': 'ORG', 'GPE': 'LOC', 'LOC': 'LOC',
        'PRODUCT': 'MISC', 'WORK_OF_ART': 'MISC', 'LAW': 'MISC', 'LANGUAGE': 'MISC',
        'EVENT': 'MISC', 'NORP': 'MISC'
    }
    
    for i, (sentence, orig_tokens) in enumerate(zip(sentences, original_tokens)):
        # Process the sentence with spacy
        doc = nlp(sentence)
        spacy_tokens = [token.text for token in doc]
        alignment = AlignTokens(spacy_tokens, orig_tokens)
        # Initialize predictions as 'O' (non-entity)
        word_predictions = ['O'] * len(orig_tokens)
        # Iterate through spacy's named entities and map to IOB2 format
        for ent in doc.ents:
            if ent.label_ in label_map:
                start_token = alignment.get(ent.start, -1)
                end_token = alignment.get(ent.end - 1, -1) + 1
                if start_token != -1 and end_token != -1:
                    for j in range(start_token, end_token):
                        if j < len(word_predictions):
                            if j == start_token:
                                word_predictions[j] = f'B-{label_map[ent.label_]}'
                            else:
                                word_predictions[j] = f'I-{label_map[ent.label_]}'
        
        all_predictions.append(word_predictions)
    return all_predictions

def GetHuggingFacePredictions(ner_pipeline, sentences):
    """
    For a list of sentences:
        generate the predictions from the model
        align these predictions with the original words in the sentence.
    ----------
    Parameters:
    ner_pipeline : transformers.Pipeline
        The NER pipeline to use for predictions.
    sentences : List[str]
        List of sentences to process.
    ----------
    Returns:
    all_predictions : List[List[str]]
        Predictions for each word in each sentence, in IOB2 taging format.
    """
    all_predictions = []
    
    for sentence in sentences:
        # Process the sentence with HF model
        words = sentence.split()
        token_predictions = ner_pipeline(sentence)
        # Initialize all predictions as 'O' (not an NE)
        word_predictions = ['O'] * len(words)
        # Iterate through model's named entities and map to IOB2 format
        for pred in token_predictions:
            start_word_index = len(sentence[:pred['start']].split())
            end_word_index = len(sentence[:pred['end']].split())
            
            for i in range(start_word_index, end_word_index):
                if i < len(word_predictions):
                    if i == start_word_index:
                        word_predictions[i] = 'B-' + pred['entity_group']
                    else:
                        word_predictions[i] = 'I-' + pred['entity_group']
        
        all_predictions.append(word_predictions)
    
    return all_predictions



def EvaluateNERModel(model_name, use_debug_prints = False):
    """
    Evaluate a Named Entity Recognition (NER) model on the CoNLL-2003 dataset.
        -loads a pre-trained model
        -processes the CoNLL-2003 test set
        -makes predictions
        -evaluates the model's performance
    ----------
    Parameters:
    model_name : str
        The name or path of the pre-trained model to evaluate.
    use_debug_prints : bool (default = False)
        Print some sample outputs to validate the code works.
    ----------
    Returns:
    evaluation_message : str
        Precision, recall, and F1-score for each entity type.
    """
    # Load the CoNLL-2003 dataset
    dataset = load_dataset("conll2003", trust_remote_code=True)
    test_dataset = dataset["test"]

    # Set up the device (GPU if available, else CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")


    if model_name == 'en_core_web_sm':
        # Load Spacy model
        nlp = spacy.load(model_name)
    else:
        # Load the pre-trained model and tokenizer from HuggingFace
        model = AutoModelForTokenClassification.from_pretrained(model_name)
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        ner_pipeline = pipeline("ner", device=device, model=model, tokenizer=tokenizer, aggregation_strategy="simple")

    # Convert numeric labels to string labels
    id2label = {i: label if label != "O" else "O" for i, label in enumerate(dataset["train"].features["ner_tags"].feature.names)}
    true_labels = [[id2label[label] for label in sentence] for sentence in test_dataset["ner_tags"]]

    # Prepare sentences and get predictions
    test_sentences = [" ".join(tokens) for tokens in test_dataset["tokens"]]
    if model_name == 'en_core_web_sm':
        pred_labels = GetSpacyPredictions(nlp, test_sentences, test_dataset["tokens"])
    else:
        pred_labels = GetHuggingFacePredictions(ner_pipeline, test_sentences)


    if use_debug_prints: # Debugging Help
        print(f"Number of true label sequences: {len(true_labels)}")
        print(f"Number of predicted label sequences: {len(pred_labels)}")

        for i in range(5):
            print(f"\nExample {i+1}:")
            print("Sentence:", test_sentences[i])
            print("True labels:", true_labels[i])
            print("Predicted labels:", pred_labels[i])
            print(f"True labels length: {len(true_labels[i])}")
            print(f"Predicted labels length: {len(pred_labels[i])}")

        # Check if lengths match for all samples
        mismatched = [i for i in range(len(true_labels)) if len(true_labels[i]) != len(pred_labels[i])]
        if mismatched:
            print(f"Mismatched lengths found in {len(mismatched)} samples. First 5 mismatched indices: {mismatched[:5]}")

    # Evaluate and return the classification report
    return classification_report(true_labels, pred_labels, mode='strict', scheme=IOB2)

if __name__ == "__main__":
    model_names = ['en_core_web_sm', 'dslim/bert-base-NER', 'dslim/bert-large-NER', 'huggingface-course/bert-finetuned-ner', '51la5/roberta-large-NER', 'Jean-Baptiste/roberta-large-ner-english']
    for model_name in model_names:
        print(f"Evaluating model: {model_name}")
        evaluation_message = EvaluateNERModel(model_name)
        print(evaluation_message)
        